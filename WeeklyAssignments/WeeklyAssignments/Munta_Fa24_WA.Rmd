---
title: "D2SC: Weekly Assignments"
author: "Ayush Munta"
date: "`r Sys.Date()`"  
output:
  html_document:
    toc: true
    toc_float: true
---

# Inital Loading

```{r}
library(tidyverse)
library(ggdist)
```

# Week 1

I went to <http://google.com> and looked up "how to load library in R". From there, I went to images, and found an example after looking a couple photos. I checked that it was working by typing in what I saw in a chunk, and then I ran the chunk of code.

```{r}
?tidyverse
```

Description

The 'tidyverse' is a set of packages that work in harmony because they share common data representations and 'API' design. This package is designed to make it easy to install and load multiple 'tidyverse' packages in a single step. Learn more about the 'tidyverse' at <https://www.tidyverse.org>.

# Assignment 2

```{r}
analogy_data <- read_csv("tidy_data/MFIndD_analogy.csv")

```

1.  qualtrics_id has the unique identifier for each participant

```{r}
num_rows <- analogy_data %>%
  summarise(total_rows = n())

num_columns <- analogy_data %>%
  summarise(total_columns = ncol(analogy_data))

num_rows
num_columns
```

2A. There are 792 rows and 6 columns. These numbers are found by running the summarise() function from dplyr in conjunction with n() or ncol(). Furthermore, these also show up while running read_csv() from the readr package or simply using dim() which is a base R package

```{r}
num_people <- analogy_data %>%
  distinct(qualtrics_id) %>%
  count()

num_people
```

2B. There are 99 people in this data set. This number is found by finding the distinct number of qualtrics_id's (which represent participants), and then using count() to count them.

```{r}
trial_counts <- analogy_data %>%
  count(qualtrics_id) %>%                    
  distinct(n)                           

trial_counts
```

2C. Everyone from the data has the same number of trials. They each have 8 in this case. This is found by using count() to return the number of trials for each participant, and then using distinct to simply by seeing how many unique value there are. In this case, since it returned one value (8) that means everyone had the same amount of trials.

# Assignment 3

```{r}
relational_summary <- analogy_data %>%
  group_by(qualtrics_id) %>%  
  summarise(relational_match_count = sum(response_type == "Rel"))  


relational_summary
```

```{r}
library(ggplot2)  
```

```{r}

ggplot(relational_summary, aes(x = relational_match_count)) +
  geom_histogram(binwidth = 1) +
  labs(title = "Histogram of Relational Matches",
       x = "Number of Relational Matches",
       y = "Frequency") +
   scale_x_continuous(breaks = seq(0, 8, by = 1)) +
  theme_minimal()
```

It seems the extremes (0 and 8) are the most common relational matches, while 5 has none.

```{r}
wide_data <- analogy_data %>%
  select(qualtrics_id, trial_number, response_type) %>%  
  pivot_wider(names_from = trial_number, values_from = response_type)


wide_data

```

```{r, eval=FALSE}

ggplot(relational_summary) +
  geom_histogram(binwidth = 1) +
  labs(title = "Histogram of Relational Matches",
       x = "Number of Relational Matches",
       y = "Frequency")
```

I think a common error might be forgetting to have defined the x aesthetic, which is required by geom_histogram(). This will throw the error:

Error in `geom_histogram()`: ! Problem while computing stat. Caused by error in `setup_params()`: ! `stat_bin()` requires an x or y aesthetic.

This is because the function needs to know what variable to use for the x or y axis.

# Assignment 4

1.  

```{r}
rei_data <- read_csv("tidy_data/MFIndD_REI.csv")

head(rei_data)


str(rei_data)
```

The column type of the "response" is a chr type and "scored_response" is of the num (double) type. This is because resposne hold numerical values in the form of a character but "scored_reponse" is a double. 2.

```{r}

rei_data <- rei_data %>%
  mutate(response = str_trim(response),             
         response = str_to_lower(response),   
         response_numeric = case_when(
           response %in% c("strongly disagree", "1") ~ 1,
           response %in% c("disagree", "2")          ~ 2,
           response %in% c("neutral", "3")           ~ 3,
           response %in% c("agree", "4")             ~ 4,
           response %in% c("strongly agree", "5")    ~ 5,
           TRUE                                       ~ NA_real_
         ))

```

3.  

```{r}
rei_data <- rei_data %>%
  mutate(new_scored_response = ifelse(!is.na(rev_scoring) & rev_scoring == "neg",
                                      6 - response_numeric,
                                      response_numeric))
rei_data
```

4.  

```{r}
match_summary <- sum(rei_data$new_scored_response == rei_data$scored_response, 
                     na.rm = TRUE)

total_rows <- nrow(rei_data)
mismatch_summary <- total_rows - match_summary


print(paste("Number of matches:", match_summary))
print(paste("Number of mismatches:", mismatch_summary))


```

# Assignment 5

1a.

```{r}

rei_summary <- rei_data %>%
  group_by(qualtrics_id, sub_type) %>%
  summarize(score = sum(scored_response), .groups = "drop")

rei_summary

```

1b.

```{r}

na_scores <- rei_summary %>%
  filter(is.na(score))

na_scores

```

As you can see, using default NA treatment, there are NA scores.

1c.

```{r}
rei_summary <- rei_data %>%
  group_by(qualtrics_id, sub_type) %>%
  summarize(score = sum(scored_response, na.rm = TRUE), .groups = "drop")


rei_summary

```

2.  

```{r}
combined_data <- left_join(rei_summary, relational_summary, by = "qualtrics_id")

combined_data
```

```{r}

ggplot(combined_data, aes(x = relational_match_count, y = score, color = sub_type)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  
  labs(
    title = "REI Score vs. Relational Match Count",
    x = "Relational Match Count (Analogy Score)",
    y = "REI Score"
  ) +
  theme_minimal() 


```

In this scatter plot, there doesn't seem to be a strong correlation between REI score and the relational match count. Nonetheless, you can sees RR and RE tend to have higher overall scores; they also seem to grow as relational match count increases, along with EE. EA seems to have an inverse relationship.

# Assignment 6

1.  

```{r}
probtask_data <- read_csv("tidy_data/MFIndD_probtask.csv")
```

2.  

```{r}
distinct_conditions <- probtask_data %>%
  distinct(condition) %>% 
  pull(condition)

distinct_conditions


mean_reaction_times <- c()  
conditions <- c()           


for (i in seq_along(distinct_conditions)) {
  condition_data <- probtask_data %>%
    filter(condition == distinct_conditions[i])
  

  conditions <- c(conditions, distinct_conditions[i])
  mean_reaction_times <- c(mean_reaction_times, mean(condition_data$rt, na.rm = TRUE))
}

for (i in seq_along(conditions)) {
  cat(conditions[i], ":", mean_reaction_times[i], "\n")
}



```

There are 4 distinct values in the condition column.

3.  

```{r}
# with across
probtask_summary_across <- probtask_data %>%
  group_by(condition) %>%
  summarise(
    across(c(rt, correct), 
           list(mean = ~ mean(.x, na.rm = TRUE)), 
           .names = "{col}_mean")
  )


probtask_summary_across

#  without across()
probtask_summary <- probtask_data %>%
  group_by(condition) %>%
  summarise(
    mean_reaction_time = mean(rt, na.rm = TRUE),
    accuracy = mean(correct == 1, na.rm = TRUE)
  )


probtask_summary


```

# Assignment 7

1.  

```{r}
prob_data <- read_csv("tidy_data/MFIndD_probtask.csv")

```

```{r}
prob_data %>%
group_by(condition) %>%
summarise(across(c(rt, correct), mean)) %>%
pivot_longer(c(rt, correct)) %>%
ggplot(aes(y = value, x = condition)) +
geom_point(color = "red") +
facet_wrap(~name, scales = "free")
```

1a. It appears accuracy is highest in the blob_shifted condition, but it drops a bit in the block_stacked and dots_EqSizeRand conditions. For reaction time, itâ€™s longest in blob_shifted and dots_EqSizeSep, which might mean participants needed more time to figure those out.

1b. The first thing I noticed in the graphs was the seemingly large distance on how the red dots are spread out. Obviously, this is because of the scaling, but it also seems that there are not really any mediary points between the highs and the lows.

1c. Since the graphs only show the mean, it makes it hard to grab a sense of what it really means as it generalizes, especially since we cant see the spread of reaction time and accuracy. Therefore,making me very interested in any possible outliers.

2.  

```{r}

prob_data_prop <- prob_data %>%
  group_by(SubID, condition) %>%
  summarise(prop_corr = mean(correct, na.rm = TRUE)) %>%
  ungroup()

prob_data_prop %>%
  group_by(condition) %>%
  summarise(mean_prop_corr = mean(prop_corr, na.rm = TRUE)) %>%
  ggplot(aes(x = condition, y = mean_prop_corr)) +
  geom_point(color = "red") +
  labs(title = "Mean Proportion Correct by Condition",
       x = "Condition",
       y = "Mean Proportion Correct") +
  theme_minimal()

```

This is less misleading because it shows the mean for accounting for participants, it does not summarize the entire data set and lets us account for accuracy per participant. This makes it a better representation of individual differences.

3.  

```{r}
prob_data_prop %>%
  ggplot(aes(x = condition, y = prop_corr)) +
  stat_summary(geom = "point", fun = mean, color = "blue", size = 3) +  
  ggdist::stat_slab(aes(fill = condition), alpha = 0.3) +         
  labs(title = "Proportion Correct with Distribution by Condition",
       x = "Condition",
       y = "Proportion Correct") +
  theme_minimal() 

```

This plot shows a visualization of the spread of accuracy scores. The width indicated how frequently a score occurs, with wider sections being more common scores.

I used a minimal theme and gave each slab a different color and made them a bit transparent.

# Assignment 8

1.  Added table of contents above.

2.  

```{r}
summary_probdata <- prob_data %>%
  group_by(SubID, condition) %>%
  summarise(
    rt = mean(rt, na.rm = TRUE),
    correct = mean(correct, na.rm = TRUE)) %>%
  ungroup() 
head(summary_probdata)
```

3..

```{r}
ggplot(summary_probdata, aes(x = rt, y = correct, color = condition)) +
  geom_point() +
   labs(
    title = "Reaction Time vs Accuracy by Condition",
    x = "Reaction Time (ms)", 
    y = "Proportion Correct") +
  theme_minimal()
```

```{r}
ggplot(summary_probdata, aes(x = rt, y = correct, color = condition)) +
  geom_point() +
  facet_wrap(~condition) +
  labs(
    title = "Reaction Time vs Accuracy by Condition",
    x = "Reaction Time (ms)", 
    y = "Proportion Correct") +
  theme_minimal()
```

4.  

All of these plots demonstrate a **positive** correlation. Although the way in the increase seems to differ, *blob_shifted* and *dots_EqSizeSep* growth seems to taper down. While *blob_stacked* and *dots_EqSizeRand* growth seem no sign of slowing down.
